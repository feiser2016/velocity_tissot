--- include/linux/perf_event.h
+++ include/linux/perf_event.h
@@ -684,25 +689,14 @@ static inline void perf_fetch_caller_regs(struct pt_regs *regs)
 static __always_inline void
 perf_sw_event(u32 event_id, u64 nr, struct pt_regs *regs, u64 addr)
 {
-	if (static_key_false(&perf_swevent_enabled[event_id]))
-		__perf_sw_event(event_id, nr, regs, addr);
-}
-
-DECLARE_PER_CPU(struct pt_regs, __perf_regs[4]);
+	struct pt_regs hot_regs;
 
-/*
- * 'Special' version for the scheduler, it hard assumes no recursion,
- * which is guaranteed by us not actually scheduling inside other swevents
- * because those disable preemption.
- */
-static __always_inline void
-perf_sw_event_sched(u32 event_id, u64 nr, u64 addr)
-{
 	if (static_key_false(&perf_swevent_enabled[event_id])) {
-		struct pt_regs *regs = this_cpu_ptr(&__perf_regs[0]);
-
-		perf_fetch_caller_regs(regs);
-		___perf_sw_event(event_id, nr, regs, addr);
+		if (!regs) {
+			perf_fetch_caller_regs(&hot_regs);
+			regs = &hot_regs;
+		}
+		__perf_sw_event(event_id, nr, regs, addr);
 	}
 }
 
